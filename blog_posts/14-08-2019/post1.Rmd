---
title: "Função de Verossimilhança"
author: "Fernando de Souza Bastos"
#date: "`r format(Sys.time(), '%B %e, %Y')`"
date: "16 de agosto de 2019"
output:
  html_document:
    fig_caption: yes
    force_captions: yes
    highlight: pygments
    toc: yes
    #Sumário flutuante
    #toc_float: true
    #numerar seções
    number_sections: true
    #Mostrar ou esconder os códigos (show ou hide)
    code_folding: hide
    #Diversos modelos de documentos ver outros em http://bootswatch.com/
    theme: united
    header-includes:
       \usepackage{array}
       \usepackage{multirow}
bibliography: bibfile.bib  
includes:
     keep_tex: yes
fontsize: 11pt
geometry: margin=1in
graphics: yes
#  pdf_document:
#    fig_caption: yes
#    keep_tex: yes
#    number_sections: yes
comments: yes
tags: [Distribuição Normal, otimização, R]
---

***

```{r,echo = FALSE}
options(OutDec=",")
```


```{r setup, include=FALSE}
require(knitr)
require(kfigr)
library(kableExtra)
options(knitr.table.format = "latex")
knitr::opts_chunk$set(echo = TRUE,fig.align = "center",message=FALSE, 
                      warning=FALSE,fig.height=5, fig.width=7)
```

# Introdução
<p style="text-align: justify;">
Seja $f(\mathbf{x}|\theta)$ a função densidade de probabilidade (fdp) ou função de 
probabilidade (fp) conjunta da amostra $X=(X_{1},\cdots,X_{n}).$ Então, dado que 
$X=x$ é observado, a função de $\theta$ definida por
</p>
$$
L(\theta|\mathbf{x})=f(\mathbf{x}|\theta)
$$
<p style="text-align: justify;">
é chamada de função de verossimilhança. Se $X$ é um vetor aleatório discreto, então 
$L(\theta|\mathbf{x})=P_{\theta}(X=x).$ Se $X$ é uma variável aleatória contínua com valor real e se a fdp de $X$ é contínua em $x,$ então, para $\epsilon$ pequeno, $P_{\theta}(x-\epsilon<X<x+\epsilon)\approx 2\epsilon{}f(\mathbf{x}|\theta)=2\epsilon{}L(\theta|\mathbf{x})$ (lembrem-se de integral de Riemann). Apesar de parecer que a função de verossmilhança é igual a uma fdp ou a uma fp, há uma distinção sútil, pois no caso da fdp ou fp consideramos $\theta$ fixo e $x$ variável. No caso da função de verossimilhança $L(\theta|\mathbf{x}),$ consideramos que $x$ é ponto amostral observado (fixo) e que $\theta$ é a variável assumindo valores em um espaço paramétrico $\Theta$ qualquer. 
</p>

<p style="text-align: justify;">
Considere uma variável aleatória $X$, cujo comportamento pode ser explicado por duas hipóteses (hipóteses $A$ e $B$) que desejamos comparar. Realizamos um estudo e observamos um valor $x$ de $X.$ O que as hipóteses dizem a respeito dessa observação?
</p>
- A hipótese $A$ implica que $X=x$ seria observado com probabilidade $p_{A}(x);$
- A hipótese $B$ implica que $X=x$ seria observado com probabilidade $p_{B}(x);$

No processo de investigação científica, no entanto, o que interessa é a pergunta: 

<p style="text-align: center;">
"*O que a observação de $X = x$ diz a respeito das hipóteses $A$ e $B?$*"
</p>
<p style="text-align: justify;">
A Lei da Verossimilhança afirma que, no caso discreto, a observação $X = x$ é uma evidência que favorece a hipótese $A$ sobre a hipótese $B$ se, e somente se, 
</p>
\begin{align}
P_{A}(X=x)=L(A|x)>L(B|x)=P_{B}(X=x)
\end{align}

Mais ainda, a Lei da Verossimilhança implica que a *Razão de Verossimilhança*
\begin{align}
\dfrac{P_{A}(X=x)}{P_{B}(X=x)}=\dfrac{L(A|x)}{L(B|x)}
\end{align}
mede a *força de evidência* em favor da hipótese $A$ sobre a hipótese $B.$ No caso contínuo, escreveríamos,
$$
\dfrac{P_{A}(x-\epsilon<X<x+\epsilon)}{P_{B}(x-\epsilon<X<x+\epsilon)}\approx 
\dfrac{L(A|\mathbf{x})}{L(B|\mathbf{x})}.
$$

## Exemplo
<p style="text-align: justify;">
O número de mensagens eletrônicas (em centenas) recebidas por um provedor em horário comercial pode ser modelado por uma distribuição de probabilidade. Há duas hipóteses que iremos considerar:
</p>
- Hipótese A: o número médio de mensagens eletrônicas (em centenas) recebidas por dia é 15;

- Hipótese B: o número médio de mensagens  (em centenas) recebidas recebidas por dia é 25;
<p style="text-align: justify;">
Observou-se, durante um dia qualquer, 2000 mensagens. Neste caso, o número de mensagens $X$ é uma variável aleatória e a distribuição de _Poisson_ é uma candidata para a modelagem, pois trata-se de dados de contagem. Assim, se $X$ tem distribuição _Poisson_, sua função densidade é dada por:
</p>
$$
P(X=x)=\dfrac{e^{-\mu}\mu^{x}}{x!},
$$
em que $\mu$ é o número médio de mensagens. Logo, as probabilidades de acordo com as hipóteses são:

- Hipótese A: $\mu=15$
$$
p_{A}(20)=\dfrac{e^{-15}15^{20}}{20!}=0.04181031.
$$
- Hipótese B: $\mu=25$
$$
p_{B}(20)=\dfrac{e^{-25}25^{20}}{20!}=0.05191747.
$$
<p style="text-align: justify;">
Logo, a observação $X=20$ favorece a hipótese $B$ sobre a hipótese $A.$ A *força de evidência* em favor de $B$ sobre $A$ é
</p>
$$
\dfrac{p_{B}(20)}{p_{A}(20)}=\dfrac{0.05191747}{0.04181031}=1.241738.
$$
<p style="text-align: justify;">
Ou seja, pode se dizer que a observação $X = 20$ é evidência que a hipótese $B$ é aproximadamente 1.24 vezes mais verossímil que a hipótese $A.$
</p>

## Discussão sobre exemplo anterior

<p style="text-align: justify;">
Notemos que ao comparar as hipóteses utilizamos a _função de densidade_ da distribuição _Poisson_:
</p>
$$
P(X=x)=\dfrac{e^{-\mu}\mu^{x}}{x!}
$$
<p style="text-align: justify;">
em que $x$ é o valor de uma observação da variável aleatória Poisson e $\mu$ é o seu parâmetro. A observação $X = 20$ foi dada e, portanto, o valor de $x$ é conhecido e fixo. Assim, a função utilizada foi 
</p>
$$
P(X=20)=\dfrac{e^{-\mu}\mu^{20}}{20!}.
$$
<p style="text-align: justify;">
Essa expressão não é mais uma função do valor da observação $x,$ e sim uma função do parâmetro $\mu,$ que variou da hipótese $A$ para hipótese $B.$ 
</p>
<p style="text-align: justify;">
Sempre que numa função densidade, ou função de probabilidade, a observação for fixada e o parâmetro desconhecido (variável), não se tem mais uma função densidade, mas uma função de verossimilhança. Esta última indica a verossimilhança de uma dada hipótese, por exemplo a hipótese $A$ em que $\mu = 15$, dado que observou-se $X = 20$. Para tornar mais claro este conceito se utiliza uma notação diferente para a função de verossimilhança:
</p>
$$
L(hipótese|dados)\ \textrm{ou}\  L(A|X=x)\ \textrm{ou}\ L(\mu|X=x)
$$

Assim, de acordo com o exemplo anterior, temos:
$$
L(\mu|X=20)=\dfrac{e^{-\mu}\mu^{20}}{20!}
$$
<p style="text-align: justify;">
A `r figr("fig1", TRUE, type="Figura")` apresenta o gráfico dessa função para valores de $\mu$ entre 10 e 50. Notemos que o valor da observação influencia fortemente o comportamento da função de verossimilhança, o que pode ser observado na `r figr("fig2", TRUE, type="Figura")`.
</p>
```{r fig1,echo=TRUE,anchor="Figura"}
x <- 20
mu <- seq(10, 50, l = 100)
lmu <- (exp(-mu)*(mu^x))/factorial(x)
expr = expression(L*(mu ~ "|" ~ X==20))
plot(mu, lmu, type = "l", xlab = expression(mu), ylab = expr, main = "Figura 1: Verossimilhança de uma distribuição Poisson para x=20")
```

```{r fig2,echo=TRUE,anchor="Figura"}
mu <- seq(10, 50, l = 100)

lmu<-function(x,mu){
  lmu1<-(exp(-mu)*(mu^x))/factorial(x)
  return(lmu1)
}
expr = expression(L*(mu ~ "|" ~ X==x))
plot(mu, lmu(10,mu), type = "l", xlab = expression(mu), ylab = expr, main = "Figura 2: Verossimilhança para diferentes valores observados de X")
lines(mu, lmu(13,mu),col=2,lty=2, lwd=1)
lines(mu, lmu(17,mu),col=3,lty=3, lwd=2)
lines(mu, lmu(20,mu),col=4,lty=4, lwd=3)
lines(mu, lmu(25,mu),col=5,lty=5, lwd=3)
lines(mu, lmu(40,mu),col=6,lty=6, lwd=2)
legend(40, 0.12, c(expression(x==10), 
                    expression(x==13),
                    expression(x==17),
                    expression(x==20),
                    expression(x==25),
                    expression(x==40)), 
       col=1:6, 
       lwd=c(1,1,2,3,3,2), 
       lty=c(1,2,3,4,5,6))
```

_________________________________________________

## Múltiplas Observações
<p style="text-align: justify;">
Em geral, quando fazemos qualquer estudo estatístico, trabalhamos com várias observações independentes para compor uma amostra. Assim, ao assumir uma hipótese $A$ como verdadeira, a probabilidade de se obter uma amostra $X=(X_{1},\cdots,X_{n}),$ composta de $n$ observações independentes de $X$ é dada por 
</p>
$$
P(X|A)=P(X=x_{1}|A)P(X=x_{2}|A)\dots{}P(X=x_{n}|A).
$$
<p style="text-align: justify;">
Ou seja, a probabilidade de se obter a amostra observada, dado a hipótese $A,$ é igual ao produto das probabilidades das observações individuais, dado a hipótese $A.$ Da mesma forma, a função de verossimilhança de uma amostra composta de observações independentes será o produto das funções de verossimilhança das observações individuais, ou seja,
</p>
\begin{align}
L(A|X)&=L(A|X=x_{1})L(A|X=x_{2})\dots L(A|X=x_{n})\\
&={\displaystyle \prod_{i=1}^{n}L(A|X=x_{i})}
\end{align}

## Exemplo
<p style="text-align: justify;">
Suponha que tenhamos contabilizado durante 10 dias as mensagens recebidas. Os resultados são apresentados na Tabela 1 abaixo.
</p>
$$
\begin{array}{cccc}
\hline
Dia&N. de Mensagens&Verossimilhança&Verossimilhança\\
(i)&(X=x_{i})&\mu=15&\mu=25\\
\hline
1 &20&0.04181031  &0.05191747\\
2 &23&0.01327967  &0.07634203\\
3 &25&0.004979876 &0.07952295\\
4 &22&0.02036216  &0.07023467\\
5 &27&0.001596114 &0.07080035\\
6 &25&0.004979876 &0.07952295\\
7 &23&0.01327967  &0.07634203\\
8 &28&0.0008550612&0.0632146 \\
9 &29&0.000442273 &0.05449534\\
10&21&0.0298645   &0.06180651\\
\hline
&{\displaystyle \prod_{i=1}^{10}}&6.711593\times 10^{-23}&2.025927\times 10^{-12}\\
\hline
\end{array}
$$

<!--|Dia             |N. de Mensagens |Verossimilhança       |Verossimilhança|
|----------------|----------------|----------------------|---------------|
|$(i)$           |$(X=x_{i})$     |$\mu=15$              |$\mu=25$       |
|                |                |                      |               |
|1 |20|0,04181031  |0,05191747|
|2 |23|0,01327967  |0,07634203|
|3 |25|0,004979876 |0,07952295|
|4 |22|0,02036216  |0,07023467|
|5 |27|0,001596114 |0,07080035|
|6 |25|0,004979876 |0,07952295|
|7 |23|0,01327967  |0,07634203|
|8 |28|0,0008550612|0,0632146 |
|9 |29|0,000442273 |0,05449534|
|10|21|0,0298645   |0,06180651|
|  |${\displaystyle \prod_{i=1}^{10}L(\theta|X=x_{i})}$|6,711593e-23|2,025927e-12|
|                |                |                      |               |
-->
<p style="text-align: justify;">
Observamos na Tabela acima que a verossimilhança apresenta um valor próximo de zero, isso porque a 
verossimilhança da amostra é o produto da verossimilhança das observações. Além disso, observamos que a hipótese $B$ permanece como a hipótese mais verossímil.
</p>
## Log-Verossimilhança
<p style="text-align: justify;">
Na maioria dos casos, especialmente quando vamos diferenciar a função de verossimilhança, é mais fácil trabalhar com o logaritmo natural da função de verossimilhança do que trabalhar diretamente com $L(\theta|X).$ Assim, vamos utilizar 
</p>
$$
\mathcal{L}(\theta|X=x)=log{(L(\theta|X))}
$$
<p style="text-align: justify;">
É fácil observar que o valor numérico da verossimilhança é geralmente (não necessariamente) menor do que um. Logo, o logaritmo desse valor é negativo. Por isso, as vezes, trabalhamos com a função log-verossimilhança negativa, ou seja, com
</p>
$$
\mathcal{L}(\theta|X=x)=-log{(L(\theta|X))},
$$
<p style="text-align: justify;">
nesse caso, se o valor da verossimilhança de uma amostra com muitas observações é um número positivo muito pequeno, próximo de zero, o valor da log-verossimilhança negativa será um número positivo numa escala mais fácil de trabalhar. 
</p>
<p style="text-align: justify;">
Por outro lado, o fato da transformação incluir uma mudança de sinal implica que o comportamento da função de log-verossimilhança negativa é oposto ao comportamento da função de verossimilhança. Isso significa que a hipótese com maior verossimilhança negativa terá menor log-verossimilhança.
</p>

# Estimadores de Máxima Verossimilhança
<p style="text-align: justify;">
O método da Máxima Verossimilhança consiste em estimar os parâmetros de um modelo utilizando as estimativas que tornam máximo o valor da função de verossimilhança. Isso é equivalente a encontrar o valor para o parâmetro que torna máxima a função de log-verossimilhança ou miníma a função log-verossimilhança negativa. Assim, considere a definição seguinte:
</p>
<p style="text-align: justify;">
_Definição:_ Para cada ponto amostral $x,$ seja $\hat{\theta}(x)$ um valor de parâmetro no qual $L(\theta|x)$ atinge seu máximo como uma função de $\theta,$ com $x$ mantido fixo. Um _estimador de máxima verossimilhança_ (EMV) do parâmetro $\theta$ com base em uma amostra $x$ é $\hat{\theta}(x).$ 
</p>

<p style="text-align: justify;">
Para utilizar cálculos bivariados a fim de verificar que uma função $f(\theta_{1},\theta_{2})$ possui um máximo local em $(\hat{\theta}_{1},\hat{\theta}_{2}),$ deve ser mostrado que as seguintes três condições se mantêm.
</p>

i) As derivadas parciais de primeira ordem são 0,
$$
\dfrac{\partial}{\partial\theta_{1}}f(\theta_{1},\theta_{2})|_{\theta_{1}=\hat{\theta}_{1},\theta_{2}=
\hat{\theta}_{2}}=0\quad \textrm{e}\quad 
\dfrac{\partial}{\partial\theta_{2}}f(\theta_{1},\theta_{2})|_{\theta_{1}=\hat{\theta}_{1},\theta_{2}=
\hat{\theta}_{2}}=0
$$
ii) Pelo menos uma derivada de segunda ordem é negativa,
$$
\dfrac{\partial^{2}}{\partial\theta_{1}^{2}}f(\theta_{1},\theta_{2})|_{\theta_{1}=\hat{\theta}_{1},
\theta_{2}=\hat{\theta}_{2}}<0\quad \textrm{ou}\quad 
\dfrac{\partial^{2}}{\partial\theta_{2}^{2}}f(\theta_{1},\theta_{2})|_{\theta_{1}=\hat{\theta}_{1},
\theta_{2}=\hat{\theta}_{2}}<0
$$
iii) O jacobiano das derivadas parciais de segunda ordem é positivo,

$$
\left|\begin{array}{rrr}
\dfrac{\partial^{2}}{\partial\theta_{1}^{2}}f(\theta_{1},\theta_{2}) & \dfrac{\partial^{2}}{\partial\theta_{1}\partial\theta_{2}}f(\theta_{1},\theta_{2}) \\
\dfrac{\partial^{2}}{\partial\theta_{2}\partial\theta_{1}}f(\theta_{1},\theta_{2}) & \dfrac{\partial^{2}}{\partial\theta_{2}^{2}}f(\theta_{1},\theta_{2})
\end{array}\right|_{\theta_{1}=\hat{\theta}_{1},\theta_{2}=\hat{\theta}_{2}}=\dfrac{\partial^{2}}{\partial\theta_{1}^{2}}f(\theta_{1},\theta_{2})\dfrac{\partial^{2}}{\partial\theta_{2}^{2}}f(\theta_{1},\theta_{2})-\Big(\dfrac{\partial^{2}}{\partial\theta_{1}\partial\theta_{2}}f(\theta_{1},\theta_{2})\Big)^{2}|_{\theta_{1}=\hat{\theta}_{1},\theta_{2}=\hat{\theta}_{2}}>0
$$
<p style="text-align: justify;">
Ou seja, para encontrar os estimadores de máxima verossimilhança são necessários todos esses cálculos. Lógico que para três ou mais parâmetros tais condições devem ser generalizadas. Além disso, tais condições satisfeitas garantem somente que os EMV são máximos locais e interiores, ainda é necessário garantir que são únicos e que não existe máximo na infinidade ou nos limites do espaço paramétrico. 
</p>

# Avaliações Assintóticas

A medida que o tamanho amostral aumenta desejamos que a sequência de estimadores $w_{1},\cdots,w_{n}$ seja uma sequência consistente, eficiente e que possua normalidade assintótica. Essas são qualidades necessárias para um bom estimador. Ser consistente significa que para $n\rightarrow \infty$ temos $w_{n}\approx \theta,$ na verdade, temos:

_Definição 1:_ Uma sequência de estimadores $W_{1}=W_{1}(X_{1}),\cdots,W_{n}=W_{n}(X_{1},\cdots,X_{n})$ é uma sequência _consistente_ de estimadores do parâmetro $\theta$ se, e somente se, para cada $\epsilon>0$ e cada $\theta\in \Theta$,
$$
{\displaystyle \lim_{n\rightarrow \infty}P_{\theta}(|W_{n}-\theta|<\epsilon)}=1
$$

_Teorema:_ Se $W_{n}$ é uma sequência de estimadores de um parâmetro $\theta$ que satisfaz,

1 - 
$$
{\displaystyle \lim_{n\rightarrow \infty}V_{\theta}(W_{n})}=0,
$$

2 - 
$$
{\displaystyle \lim_{n\rightarrow \infty}\textrm{Viés}_{\theta}(W_{n})}=0,
$$

para cada $\theta\in \Theta,$ então $W_{n}$ é uma sequência consistente de estimadores de $\theta.$

_Definição 2:_ Uma sequência de estimadores $W_{n}$ é assintoticamente eficiente para um parâmetro $\tau(\theta)$ se $\sqrt{n}(W_{n}-\tau(\theta))\rightarrow N(0,v(\theta))$ em distribuição e
$$
v(\theta)=\dfrac{[\tau'(\theta)]^{2}}{E_{\theta}\Big((\frac{\partial}{\partial\theta}\log{f(X|\theta)})^{2}\Big)},
$$
isto é, a variância assintótica de $W_{n}$ atinge o Limite inferior de Cramér-Rao.


## Exemplo: Distribuição Normal

<p style="text-align: justify;">
Suponha que observamos o vetor $(13,12,15,17,16,11,18,16,13,15)$ de valores de uma variável $X\sim N(\mu,4).$ e digamos que há duas hipóteses competindo:

- Hipótese $A:$ a média de $X$ é $\mu=13;$
- Hipótese $B:$ a média de $X$ é $\mu=15;$

<p style="text-align: justify;">
Precisamos responder qual o modelo (distribuição estatística) mais provável para se observar o vetor de valores acima? Sabemos que:
</p>
1- $X_{1},\cdots,X_{n},$ com $n=10,$ é uma amostra aleatória de $X\sim N(\mu,4);$

2- A densidade para cada observação é dada por $f(x_{i};\mu,\sigma^{2})=\dfrac{1}{2\sqrt{2\pi}}
\exp\Big\{-\dfrac{(x_{i}-\mu)^{2}}{8} \Big\};$

3- A verossimilhança é dada por $L(\mu|X)={\displaystyle \prod_{i=1}^{10}f(\mu;x_{i})};$

4- E a função log-verossimilhança é dada por:
$$
\begin{align}
L(\mu|X)=&-10\log{(2\sqrt{2\pi})}-\dfrac{1}{8}{\displaystyle \sum_{i=1}^{10}(x_{i}-\mu)^{2}}\\
=& -5\log{(8\pi)}-\dfrac{1}{8}\Big(\sum_{i=1}^{10}x_{i}^{2}-2\mu\sum_{i=1}^{10}x_{i}+10\mu^{2}\Big)
\end{align}
$$
<p style="text-align: justify;">
Notemos que ao substituir os valores observados do vetor $X,$ obtemos uma função de $\mu.$ Vamos fazer isso e encontrar o gráfico de $L(\mu|X)$ para $\mu$ variando de 0 a 20; 
</p>
```{r,fig.align='center'}
x <- c(13,12,15,17,16,11,18,16,13,15)
sx2 <- sum(x^2) 
sx <- sum(x)
mu.vals <- seq(10, 20, l = 100)
expr = expression(L*(mu ~ "|" ~ X==x))
lmu <- -5 * log(8 * pi) - (sx2 - 2 * mu.vals * sx + 10 * (mu.vals^2))/8
v=max(lmu)
plot(mu.vals, lmu, type = "l", xlab = expression(mu), ylab = expr)
abline(v=14.6,col="red")
```

Para obter o ponto de máximo calculamos a derivada de $L(\mu|X)$ em função de $\mu$ e encontramos:
$$
\dfrac{\partial L(\mu|X)}{\partial\mu}={\displaystyle \dfrac{1}{4}\sum_{i=1}^{10}(x_{i}-\mu)}
$$
Ao igualar a derivada acima a zero e resolver a equação, obtemos:
$$
\hat{\mu}={\displaystyle \dfrac{\sum_{i=1}^{10}x_{i}}{n}}
$$

Para provar que este é ponto de máximo, derivamos novamente e observamos que a segunda derivada no ponto $\hat{\mu}$ é sempre negativa.
$$
\dfrac{\partial^{2}l(\mu)}{\partial\mu^{2}}=-\dfrac{n}{\sigma^{2}}<0, \forall x\in \mathbb{R}.
$$


Observamos então que $x={\displaystyle \dfrac{\sum_{i=1}^{10}x_{i}}{10}}=14,6$ é o ponto de máximo de $L(\mu|X).$


Até este ponto, utilizei como referência os trabalhos de @Batista e @casella.

# Estudos Teóricos relacionados a Estimação de Parâmetros  

## Distribuição Normal

### Função de Distribuição Acumulada 

$$
  F(x;\mu,\sigma^{2})=\int_{-\infty}^{x}\dfrac{1}{\sqrt{2\pi}\sigma}
  \exp\Big\{-\dfrac{(t-\mu)^{2}}{2\sigma^{2}} \Big\}dt
$$
    
### Função Densidade 
  
$$
    f(x;\mu,\sigma^{2})=\dfrac{1}{\sqrt{2\pi}\sigma}
    \exp\Big\{-\dfrac{(x-\mu)^{2}}{2\sigma^{2}} \Big\}dx
$$
      
### Log-Verossimilhança
<p style="text-align: justify;">    
Sejam $X_{1},\cdots,X_{n}$ variáveis aleatórias independentes e identicamente distribuidas com distribuição normal de média $\mu$ e variância $\sigma^{2}$ desconhecidas. Segue que, para $\theta=(\mu,\sigma^{2}),$ temos
</p>

$$
L(\theta|X)=\dfrac{1}{(2\pi\sigma^{2})^{n/2}}\exp{\Big\{\Big(-\frac{1}{2}\Big){\displaystyle \sum_{i=1}^{n}\frac{(x_{i}-\mu)^{2}}{\sigma^{2}}}\Big\}},
$$
      
e, portanto,
    
$$
\mathcal{L}(\theta|X)=-\frac{n}{2}\log{(2\pi)}-\frac{n}{2}\log{\sigma^{2}}-\frac{1}{2}{\displaystyle \sum_{i=1}^{n}\frac{(x_{i}-\mu)^{2}}{\sigma^{2}}},
$$
      
### Derivadas parciais com respeito aos parâmetros (Vetor Escore)
    
\begin{align}
\dfrac{\partial}{\partial\mu}\mathcal{L}(\theta|X)&=\frac{1}{\sigma^{2}}{\displaystyle \sum_{i=1}^{n}(x_{i}-\mu)};&&\dfrac{\partial}{\partial\sigma^{2}}\mathcal{L}(\theta|X)=-\frac{n}{2\sigma^{2}}+\frac{1}{2\sigma^{4}}{\displaystyle\sum_{i=1}^{n}(x_{i}-\theta)^{2}};
\end{align}
    
### Jacobiano
    
    
$$
\left|\begin{array}{rrr}
-\frac{n}{\sigma^{2}}&-\frac{1}{\sigma^{4}}{\displaystyle \sum_{i=1}^{n}(x_{i}-\mu)}\\
-\frac{1}{\sigma^{4}}{\displaystyle \sum_{i=1}^{n}(x_{i}-\mu)}&\frac{n}{2\sigma^{4}}-\frac{1}{\sigma^{6}}{\displaystyle \sum_{i=1}^{n}(x_{i}-\mu)^{2}}
\end{array}\right|
$$

### Estimadores de Máxima Verossimilhança

Segue que, 
    
$$
\dfrac{\partial}{\partial\theta_{1}}f(\theta_{1},\theta_{2})|_{\theta_{1}=\hat{\theta}_{1},\theta_{2}=\hat{\theta}_{2}}=0\Rightarrow \hat{\mu}={\displaystyle \dfrac{\sum_{i=1}^{n}x_{i}}{n}}
$$
$$
\dfrac{\partial}{\partial\theta_{2}}f(\theta_{1},\theta_{2})|_{\theta_{1}=\hat{\theta}_{1},\theta_{2}=\hat{\theta}_{2}}=0\Rightarrow \hat{\sigma}^{2}=\dfrac{(n-1)}{n}S^{2},\quad \textrm{em que}\quad S^{2}={\displaystyle \dfrac{\sum_{i=1}^{n}(x_{i}-\hat{\mu})^{2}}{n-1}}
$$
      
Observando o jacobiano acima vemos que a condição ii) é mantida e, além disso,
$$
\left|\begin{array}{rrr}
-\frac{n}{\sigma^{2}}&-\frac{1}{\sigma^{4}}{\displaystyle \sum_{i=1}^{n}(x_{i}-\mu)}\\
-\frac{1}{\sigma^{4}}{\displaystyle \sum_{i=1}^{n}(x_{i}-\mu)}&\frac{n}{2\sigma^{4}}-\frac{1}{\sigma^{6}}{\displaystyle \sum_{i=1}^{n}(x_{i}-\mu)^{2}}
\end{array}\right|_{\mu=\hat{\mu},\sigma^{2}=\hat{\sigma}^{2}}=\dfrac{1}{\sigma^{6}}\Big[-\frac{n}{2}+\frac{n}{\sigma^{2}}{\displaystyle \sum_{i=1}^{n}(x_{i}-\mu)^{2}-\frac{1}{\sigma^{2}}\Big(\sum_{i=1}^{n}(x_{i}-\mu)\Big)^{2}}\Big]_{\mu=\hat{\mu},\sigma^{2}=\hat{\sigma}^{2}}
$$
  
$$
=\dfrac{1}{\hat{\sigma}^{6}}\Big[\dfrac{-n^{2}}{2}+\dfrac{n^{2}}{\hat{\sigma}^{2}}\hat{\sigma}^{2}-\dfrac{1}{\hat{\sigma}^{2}}\Big(\sum_{i=1}^{n}(x_{i}-\hat{\mu})\Big)^{2}\Big]=\dfrac{1}{\hat{\sigma}^{6}}\dfrac{n^{2}}{2}>0
$$
    
Logo, os pontos $\hat{\mu}={\displaystyle \dfrac{\sum_{i=1}^{n}x_{i}}{n}}$ e $\hat{\sigma}^{2}=\dfrac{(n-1)}{n}S^{2}$ são pontos de máximo e são os estimadores de máxima verossimilhança do modelo normal.

## Consistência


    
# Mensagem Final 
    
De acordo com Mario Sergio Cortella há três caminhos para o sucesso:
      
1- Ensinar o que se sabe - Generosidade Mental
    
2- Praticar o que se ensina - Coerência Ética
    
3- Perguntar o que se ignora - Humildade Intelectual
    
# Referências 

